# 목적함수

강의 자료 첫 부분에 이런 글이 나온다.

"시험에서는 틀린 만큼 합당한 벌점을 받는 것이 중요하다. 그래야 다음 시험에서 심기일전으로 공부하여 틀리는 개수를 줄일 가능성이 크기 때문이다. 틀린 개수에 상관없이 비슷한 발점을 받는다면 나태해져 성적을 올리는 데 지연이 발생할 것이다. 이러한 원리가 기계 학습에도 적용될까?"

바로 다음 페이지에 평균제곱 오차(MSE)가 나오는데, 이것이 벌점과 같은 작용을 하는 듯 하다.

평균제곱 오차는 다음과 같이 나타낸다.
![alt text](img/딥러닝_최적화/image.png)

y(정답값)와 o(예측값)의 차이가 클 수록 e 값이 커지므로, 벌점의 형태로서 적합하다고 볼 수 있다.

하지만 큰 허점이 존재한다.

![alt text](img/딥러닝_최적화/image1.png)

위 사진의 경우, 왼쪽 그림이 오른쪽 그림보다 정답값-예측값의 크기가 작으므로, 왼쪽그림의 벌점이 더 적게 나와야 정상이다.
하지만 계산을 해보니 오른쪽 신경망의 gradient 값이 더 작다.
gradient 값이 작다는 것은 '모델 파라미터를 수정할 필요가 적다는 것'을 의미한다.
벌점은 더 많이 받으면서 수정할 필요가 적은 모순적인 상황이 발생하기 때문에 이 녀석(MSE)은 목적함수로서 부적절하다고 판단할 수 있다.

## 교차 엔트로피 목적함수

Cross Entropy 라고 하는 놈인데 실제로 여러 학습 코드를 돌리면서 상당히 자주 본 친구다.
이 녀석은 적합한 목적함수임이 틀림 없을 것이다.

그 전에 먼저 엔트로피란 무엇인가?

Entropy : 정보를 표현하는 데 필요한 최소 자원량(bits의 단위로 표현 되는 0 or 1의 길이) 즉, 최소 기댓값

예시로.. 친한 친구와의 카톡 대화에서 'ㅋ'을 상대적으로 많이 치니까 P(ㅋ)=0.5 , P(술)=0.3 , P(공부)=0.01 정도로 잡을 수 있겠다.
그러므로 많이 치는 'ㅋ'을 짧 코딩하고(예: 0으로 표현) '공부'를 길게 코딩해야(예: 111로 표현) 효율적일 것이다.
요약하면, "확률이 작을수록 길이가 길어진다." 
![alt text](img/딥러닝_최적화/image2.png)

설명을 그래프로 표현하면 위 사진과 같고 이는 -log 그래프 형태를 띈다.
bit로 표현해야 되기 때문에 log의 밑은 2가 되고, 확률로써 표현해야 되기 때문에 -log2(Pi)가 되며,
기댓값을 구하기 위해 각 길이(도수)와 확률을 곱한 값을 전부 더해주어야 한다.
길이는 -log2(Pi) 인 것이고, 확률은 Pi 이므로 최종 식은

![alt text](img/딥러닝_최적화/image3.png)


하지만 Cross Entropy 에서는 이 확률들을 모두 균등하게 잡는다. P는 실제확률이고, 내가 생각한 확률은 Q로서 표현한다 (Q(ㅋ)=0.01, Q(술)=0.01, Q(공부)=0.01)
나머지 부분은 Entropy와 동일하고 P대신 Q로 바꿔주면 되기 때문에 Cross Entropy의 최종식은 Entropy 식에서 P만 Q로 바꿔주면 된다.

이를 벌점으로서 유용한지 확인하기 위해 아래 식에 대입해보면

![alt text](img/딥러닝_최적화/image4.png)

정답값과 예측값의 차이가 클 때 더 큰 벌점을 부여하는 것을 확인. 1단계는 통과했고,
그레디언트까지만 통과하면 목적함수로서 적합하다고 할 수 있다.

미분과정을 생략하고 표현하면

![alt text](img/딥러닝_최적화/image5.png)

로 나타내지고, 값을 대입해보면 그레디언트도 벌점에 비례하여 나타나는 것을 확인하였다.

결론 : Cross Entropy는 목적함수로서 적합하다!


## Softmax

Multi Classification 을 위해 사용하는데, 상대 평가가 가능하며 무조건 1보다 작고, 각 확률의 합은 1이다.
식으로 나타내면 아래와 같다.

![alt text](img/딥러닝_최적화/image6.png)

![alt text](img/딥러닝_최적화/image7.png)

Sigmoid와는 달리, softmax는
최대값을 더욱 활성화하고 작은 값을 억제하는 효과가 있다. 이는 목적에 따라 유용하게 쓸 수 있는데, 예를 들어 softmax의 출력에 따라 가장 큰 값과 두 번째 큰 값의 차이가
임곗값보다 작으면 분류를 포기하고 기각하는 전략을 쓸 수 있다.

강의 자료에 그렇게 많은 내용이 있지 않으니, 여기까지 하고 패스



# 성능 향상

## 데이터 전처리

규모 문제에 대해 다뤄보자.

사람 2명에 대한 데이터가 있다고 치자.

키 : 1.855m , 1.525m
몸무게 : 65.5kg, 45.0kg

두 사람에 대한 키 차이는 0.33 정도
두 사람에 대한 몸무게 차이는 20 정도

단위 때문에 두 특징값 차이가 70배 정도 발생한다.
이렇게 되면 첫 번째 특징에 연결된 가중치는 두 번째 특징에 연결된 가중치에 비해 70배 정도 느리게 학습되는 것이다.

또한, 위처럼 모든 특징이 양수인 경우에도 문제가 발생한다.

이는 경사 하강법에서 적용 되는 내용인데, 경사 하강법은 손실 함수를 최솟화하기 위해 사용한다.
여기서는 기울기와 학습률이 영향을 미치는데,
만약 모든 특성이 양수라면 기울기 변화가 너무 급격하게 일어날 수 있어 이를 적절히 조절하지 않으면 학습이 느리게 이루어질 수 있다.


## 표준화

규모 문제와 데이터 양수 문제를 해결해주는 것이 표준화이다.

표준화는 데이터를 평균 0, 분산 1로 변환하는 방식이다.

![alt text](img/딥러닝_최적화/image8.png)

## 정규화

데이터를 0과 1 사이의 범위로 변환하는 방식. 주로 최솟값과 최대값을 사용하여 반환

![alt text](img/딥러닝_최적화/image9.png)

데이터셋이 [1,2,3,4,5] 일 때 대입하면 모두 0과 1 사이(0과 1 포함) 범위로 조정 됨. => 규모 문제 해결

## 원 핫 인코딩
키, 몸무게 같은 데이터와 달리 성별이나, 체질(예: 태양인, 소양인 등..)은 거리 개념(물리적 크기)을 갖지 않는다.
따라서 남자가 여러명일 때 남자 1, 남자 2 이런 식으로 표현하는 게 아니라. 성별의 경우 남 녀 2개 뿐이니까 
남자면 1 0  여자면 0 1 이런 식으로 표한한다. -> 값의 개수만큼 비트를 부여한다. 

이는 수학적으로는 값이 다를 수 있지만, 그 차이가 실제 크기나 거리 개념을 의미하지 않는다라는 의미를 전달한다.

## 가중치 초기화
신경망의 가중치는 난수를 생성하여 초기화해야 한다.

이유 : 신경망에서 모든 가중치를 동일한 값으로 초기화하면, 모든 뉴런들이 동일한 값을 학습하게 되어 '대칭이 깨지지 않는다'
-> 즉, 각 뉴런이 서로 다르게 학습할 기회가 없어진다. 따라서 난수 초기화는 각 뉴런의 가중치를 다르게 설정하여 각각 다른 패턴을 학습할 수 있도록 돕는다.

가중치 초기화 시, 가우시안 정규분포 혹은 균일분포에서 값을 추출하는 데 둘 중 어떤 것을 사용해도 성능 차이는 거의 없다.
중요한 것은 초기화의 범위 설정인데,

![alt text](img/딥러닝_최적화/image10.png)

너무 작은 값으로 초기화 하면, 0에 가까운 값으로 시작하니까 정보가 사라지거나 학습이 잘 안 될수 있다
너무 큰 값으로 초기화 하면, 값이 폭주하거나, 네트워크가 불안정해져서 학습이 어려워진다.

따라서 위 사진은 '최적의 범위를 제공하는 초기화 범위 계산 공식' 정도로 알아두면 되겠다.

bias는 보통 0으로 초기화하며, 대표적으로 AlexNet 과 ResNet 에서 이를 사용하였다. 

## 모멘텀
그레디언트에 '스무딩'을 가하여 잡음 효과를 줄인다 -> 수렴 속도 향상의 효과
![alt text](img/딥러닝_최적화/image13.png)

속도 벡터 v는 이전 그레디언트를 누적한 것에 해당한다.(처음 v는 0)
알파값의 효과는 알파가 0이면 적용이 안 된 것과 같고, 
알파가 1에 가까울수록 이전 그레디언트의 가중치를 많이 사용하는 느낌. 통상적으로 0.5, 0.9, 0.99를 사용한다.


![alt text](img/딥러닝_최적화/image11.png)

검은선이 모멘텀을 적용하지 않은 것이고, 파란선이 모멘텀을 적용한 것이다.
검은선을 보면 이동량이 너무 커서 적절한 곳을 지나치는 'Overshooting'이 발생하지만, 
파란선의 경우 Overshooting 현상이 감소하였고, 검은선에 비해 적은 반복 횟수로 최적해를 찾아간다. 

### 네스테로프 모멘텀
![alt text](img/딥러닝_최적화/image12.png)

현재는 기존 모멘텀 기법을 개선한 '네스테로프 모멘텀'이 널리 사용되고 있다.
현재 v 값으로 다음 이동할 곳을 예견한 후, 예견한 곳의 그레디언트를 사용하는 것.


## 적응적 학습률
![alt text](img/딥러닝_최적화/image14.png)

학습률이 너무크면 검은선 처럼 오벼슈팅 현상이, 
학습률이 너무 작으면 파란선 처럼 수렴이 느린 현상이 발생한다.
단순히 그레디언트에 학습률 p를 곱하면 모든 매개변수가 같은 크기의 학습률을 사용하는 셈이라 최적화가 되지 못한다.
따라서 적응적 학습률은 매개변수마다(각 세타별로) 자신의 상황에 따라 다른 학습률을 조절해서 사용한다; [학습률 답금질]

AdaGrad(단순히 제곱을 더함) -> RMSProp(가중치 이동 평균) -> Adam(RMSProp + Momentum)


## Activation Function
활성값 z를 계산하고 활성함수 τ를 적용하는 과정

![alt text](img/딥러닝_최적화/image15.png)

![alt text](img/딥러닝_최적화/image16.png)

tanh의 경우 활성값이 커지면 포화상태가 되고 그레디언트가 0에 가까워지는데, 
이는 매개변수 갱신이 매우 느린 요인이 된다.

가장 오른쪽에 나와있는 그래프인 ReLU는 이러한 포화문제를 해소한다.
좀 더 쉽게 설명하자면, 면 양의 값에서는 선형이기 때문에 큰 값에서 기울기가 너무 작아져서 학습이 느려지는 문제가 없다.
반면, 음의 값에서는 출력이 0이 되기 때문에 희소한(신경망에서 많은 뉴런 또는 가중치가 0이 되는 상태) 신경망을 만든다.
예를 들어, 신경망이 처음에 무작위로 초기화되면, 대략 절반 정도의 뉴런에서 입력 값이 음수가 될 수 있다.
이 때, 음수인 뉴런들은 모두 출력이 0이 되어 학습에 영향을 미치지 않게 되는데(계산에서 제외됨), 이렇게 되면 신경망이 희소한 상태가 되어,
각 뉴런이 특정 특징을 담당하게 되며, 여러 특징을 독립적으로 학습할 수 있게 된다. 

-> 신경망은 데이터에서 다양한 패턴을 효율적으로 추출하고 학습할 수 있게 된다. 
-> 결론 : ReLU 는 참 좋은 놈이다.

## Batch Normalization
"공변량 시프트 현상을 누그러뜨리기 위해"

공변량 시프트가 뭔지도 모른다.
- 공변량 시프트란? 훈련 중에 입력 데이터의 분포가 변화하는 현상(깊은 구조의 신경망 학습이 잘 되지 않는 이유 중 하나)
- 예를 들어, 훈련 초기에는 입력 데이터의 평균값이나 표준편차가 일정했지만, 학습이 진행될수록 그 값이 달라져 모델이 적응하기 어려워짐.

배치 정규화란?
- 각 미니배치마다 출력값을 정규화하여, 각 층의 입력 분포가 일정하게 유지되도록 돕는 것
- 이는 각 층에 들어가는 데이터가 평균 0, 표준편차 1을 갖도록 정규화하는 방식임.
- 따라서 아래의 식을 모든 층에 독립적으로 적용한다

![alt text](img/딥러닝_최적화/image17.png)


 알고 있어야 하는 수식
![alt text](img/딥러닝_최적화/image18.png)

평균과 표준편차의 흔한 수식인데, 이를 미니배치마다 계산해주어야 한다는 게 포인트

최적화를 마친 후에는 노드에 평균, 분산, γ, β 를 저장해야 하므로, 노드의 개수가 100개라고 하면
400개를 저장하고 있어야한다. 그리고 예측 단계에서 각 노드는 독립적으로 아래의 식을 적용한다.

![alt text](img/딥러닝_최적화/image19.png)

CNN에서는 노드 단위가 아닌 특징 맵 단위로 코드를 적용한다. 

배치 정규화의 장점
- 가중치 초기화에 덜 민감하다
- 학습률을 크게 하여 수렴 속도 향상 가능
- 시그모이드를 활성함수로 사용하는 깊은 신경망도 학습이 이루어진다
- 드롭아웃이라는 규제 기법을 적용하지 않아도 높은 성능을 보인다


# 과잉적합에 빠지는 이유와 과잉적합을 피하는 전략
![alt text](img/딥러닝_최적화/image20.png)

사진을 보아 훈련집합의 경우, 모델용량이 작을 수록 오류율이 높고, 클 수록 오류율이 낮다.
다만 테스트 집합의 경우, 일정수준을 넘어가게 되면 훈련집합의 과잉적합으로 인해 일반화 차이가 발생하는 것을 볼 수 있다.
따라서 현대 기계 학습은 충분히 큰 용량의 신경망 구조를 설계한 다음, 학습 과정에서 여러 규제 기법을 적용하는 전략을 사용한다.

## Weight Penlaty
![alt text](img/딥러닝_최적화/image21.png)

목적함수들은 가중치 집합과 훈련집합애 영향을 끼치지만,
규제항 R은 훈련 집합과 무관하다.(가중치에만 영향)

R은 단지 가중치의 크기에 제약을 가하는 역할을한다. 즉, 데이터셋과 무관하게 원래있는 사전지식이다.
규제항은 매개변수를 작은 값으로 유지하므로 모델의 용량을 제한하는 역할을 한다.

큰 가중치에 벌칙을 가해 작은 가중치를 유지하기 위해 주로 L2 Norm 이나 L1 Norm 을 사용한다.

### L2 Norm
- 규제항 R로 L2 Norm 을 사용하는 규제기법을 가중치 감쇠(weight decay)라고 부른다. 식은 아래와 같다.
![alt text](img/딥러닝_최적화/image22.png)

- J regulized(θ;X,Y)는 정규화를 적용한 손실함수를 뜻
- J(θ;X,Y)는 원래의 손실 함수
- 뒤에 따로 있는 λ 식이 정규화 항으로, 가중치 벡터 θ = [wo, w1, w2]의 제곱합이다.
- λ는 정규화 강도를 조절하는 계수

결론적으로 가중치 값이 너무 커지는 것을 방지한다. 
-> 정규화 항은 손실 함수에 추가되는 '페널티'이다. 기존 손실함수에서 무언가를 더한다는 것은 페널티를 키운다는 뜻.
-> 따라서 가중치가 커지면 페널티값도 커져서 학습 과정에서 가중치를 작게 만드는 방향으로 업데이트가 이루어진다.

#### 그레디언트 계산
기존 L2 Norm 식에서 미분을 때리면 아래와 같이 쓸 수 있고
![alt text](img/딥러닝_최적화/image24.png)

결과적인 가중치 업데이트 식은 아래처럼 쓸 수 있다.
![alt text](img/딥러닝_최적화/image25.png)

즉, 기존의 그레디언트값에 2λwi(페널티 항) 를 더한다.
이렇게 하면 모델이 덜 복잡해지고, 일반화 성능이 좋아지는 것

#### 매개변수 갱신 수식
기본적으로 경사하강법에서 가중치 업데이트 공식은 다음과 같다.
![alt text](img/딥러닝_최적화/image26.png)

위에서 배운 L2 Norm을 적용시키면 가중치 업데이트 공식은 다음과 같고
![alt text](img/딥러닝_최적화/image27.png)

이를 정리하면 아래의 식으로 최종 정리할 수 있다.
![alt text](img/딥러닝_최적화/image28.png)

이 식의 핵심은 (1-2ρλ)θ 부분인데, 여기서 λ 값이 0보다 크다면, 
1-2ρλ는 1보다 작은값이 되고, 결과적으로 1보다 작은값이 θ(가중치)와 곱해져 가중치가 줄어들게 된다.(ρ는 learning rate로 애초에 1보다 훨씬 작은 수를 사용)
L2 정규화 자체가 가중치를 줄이고 모델 복잡도를 억제하는 데 목적이 있으므로, λ 값은 항상 0 이상으로 생각하면 된다.(0인 경우 원래 경사하강법 그대로 적용)

결론적으로 λ 식이 추가됨으로 인해 최적화 과정에서 θ값이 작아지고, 결과적으로 0(원점)에 조금 더 가까워진다.
간단하게 설명해서, 가중치를 줄여서 일반화 성능을 향상 시키게 된다.
- 가중치가 적당히 작아지면, 모델은 덜 복잡하고 매끄러운 함수가 된다.
- 복잡하지 않은 모델은 데이터의 노이즈보다는 일반적인 패턴을 학습하려고 하기 때문에, 이는 새로운 데이터에서 더 나은 성능을 제공한다.

#### 선형회귀에 적용
일단 기본적인 선형 회귀의 목표 : 주어진 입력 데이터 X와 타겟 값 Y 사이의 관계를 나타내는 가중치 w를 학습하기

선형 회귀를 수식으로 표현하면 y^ = Xw 
- X : 입력 값(특성 행렬) -> 예 : 3x2 행렬인 경우 3개의 샘플에 2개의 특성을 가진 데이터
- w : 가중치 벡터
- y^ : 모델이 예측한 출력값

선형 회귀의 핵심은 실제 값 Y와 예측값 y^의 차이를 최소화 하는 것인데, 
오차는 다음과 같이 계산할 수 있다 'Xw-y' 
- Xw : y^ (예측 출력값)
- y : 실제 출력값(레이블)

이 오차를 제곱하고 더한 값이 MSE라고 불리던 놈이다. (기본 손실함수)
![alt text](img/딥러닝_최적화/image29.png)

이 놈에 L2 정규화 항 λ를 추가하여 아래의 식을 만든다
![alt text](img/딥러닝_최적화/image30.png)

자기 자신의 내적은 제곱합과 동일하다

위 식을 미분하여 0으로 놓고 정리하면 최종적으로 아래의 식이 된다.
![alt text](img/딥러닝_최적화/image31.png)

역행렬을 곱하므로 가중치를 축소하여 원점으로 당기는 효과.
예측 단계에서는 위에서 구한 최적의 매개변수값을 사용
![alt text](img/딥러닝_최적화/image32.png)

