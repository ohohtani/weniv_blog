# LG Aimers 6기 온라인 해커톤 수료 후기

LG Aimers 6기에 참여하였고, 

![alt text](img/에이머스/에이머스_최고순위.png)

public 최고 순위 33위까지 달성하며 100명 안에 들 줄 알았으나 (100명까지만 오프라인 본선 진출)
아쉽게도 최종 private 순위는 98위까지 내려가며 첫 Aimers 수료가 이렇게 끝이 났다.

그래도 첫 참여에 엄청 낮은 순위라고 생각하지는 않기 때문에, 어떤 방식으로 점수를 올렸었는지, 어떤 것이 효과가 있고 없었는지 공유하며
최종적으로 최상위권 분들과의 코드를 비교해보며 어떤 식으로 하는 게 비슷한 종류의 대회에서 큰 효과를 볼 수 있는지 공부하고자 한다.

먼저 대회 개요는 다음과 같다.

![alt text](img/에이머스/image.png)

평가산식은 roc-auc 를 사용하기 때문에 0 혹은 1로 나타내는 것이 아닌 예상 확률값 그대로를 제출하고 점수를 받는다.

#### 1. 베이스라인 구축 & 기본 전처리

전처리도 중요하지만 일단 적절한 방식으로 실행 되어 점수가 제대로 나오는 지 확인할 수 베이스라인 코드를 먼저 만들었다.
물론 데이콘 측에서 베이스라인 코드를 제공해주긴 하지만 점수를 기대할 수 있는 코드는 아니기에 참고용으로만 사용하기에 좋다.
아무 것도 하지 않고 데이콘에서 제공하는 베이스라인 코드를 실행하여 제출하면 0.689 점이 나온다 (1점 만점)

점수가 적절히 나오는 베이스라인 코드를 만들어야 했고, 대회 초반 당시 최상위권 팀들의 점수가 0.741~2 정도였기에
0.74정도가 나오는 베이스라인 코드를 만들면 되겠다고 생각했다. 

일단 우리 팀의 경우 팀원이 5명이라서, 초반에 전처리와 베이스라인 코드 구축을 나눠서했는데,
베이스라인 코드의 경우 optuna 파라미터 튜닝 없이 XGBoost 기본 파라미터를 사용하였고, 전처리의 경우 컬럼 삭제 없어
범주형 데이터를 모두 수치형으로 변환하여 수치형 컬럼만 남긴 채로 진행하였다. -> 점수 : 0.7395

optuna 튜닝만 진행하면 0.74라인은 넘길 것 같았고, 역시나 튜닝 진행후 제출하니 0.74092가 나오며 나쁘지 않은 출발을 했다.
하지만 이 점수대는 어느 팀이든 만들 수 있었기에 매일매일 점수를 조금이라도 더 올리기 위한 노력을 해야만 했다.


#### 2. 모델 변경 & K-Fold 교차 검증 사용

데이터 분석 & 예측 관련 대회가 처음이다 보니, 모델의 종류는 어떤 것이 있는지부터 제대로 찾아보았다.
다양한 모델이 존재했지만, 성능과 사용 빈도 면에서 현재 가장 많이 사용하는 모델은 Catboost, XGBoost, LightGBM 이 세 가지 인 것 같았다.
각 모델의 대한 논문 리뷰는 블로그 다른 페이지에 작성 예정.

추가적으로, 5기에 참여했던 지인 분께서 범주형이 있는 경우 무조건 Catboost를 쓰라는 조언을 해주셨다. 범주형 데이터가 꽤나 많이 존재했던 데이터셋이었기에
지인의 말을 듣고 catboost로 변경하게 되었다. 모델만 변경하였을 때의 점수는 XGBoost를 사용할 때와 거의 동일했다. 다만 범주형 데이터를 따로 인코딩 하지 않아도 된다는 편리함 때문에
Catboost를 계속해서 사용하기로 했다.

그리고 가장 점수 변화 폭이 컸던 'K-Fold 교차 검증 사용'이다. 이 방식의 경우 0.74092였던 점수를 한 방에 0.74155까지 올려주었는데 순식간에 등수가 엄청나게 올라갔었다.
K-Fold 교차검증의 경우 아래의 사진처럼 Optuna 튜닝 코드 내에 들어가게 된다.

![alt text](img/에이머스/image1.png)

아래의 세 가지 방식을 모두 사용해보았다.

1. Optuna 내에만 k-fold 교차 검증을 넣기
2. optuna 밖의 학습 구간에서 k-fold 교차 검증을 넣기
3. 둘다 넣기

결과는 1번일 때가 가장 좋은 점수가 나왔다. 하지만 이유를 정확히 모르겠어서 상위권분들의 코드 공유를 보고나면 이해가 될 것 같다.


#### 3. 전처리 심화 과정

이제야 피쳐간 상관관계 히트맵을 켤 차례다. 
처음에 제공해주는 컬럼의 개수는 총 69개인데, 아무래도 상관계수가 너무 높아 중복의 우려가 있거나, 데이터와 무관하다 싶은 컬럼은 삭제를 해줘야한다.
상관계수 필터링만으로 69개의 컬럼에서 36개의 컬럼을 삭제하여 33개만 남겨두었다.
다른 대회 코드 공유 글들을 보면 피쳐를 1~20개 정도만 유지시키던데, 이번 대회의 경우 상위권 분들이 몇개만 남겨 두었을지, 파생변수는 어떻게 생성하셨을지 너무 궁금해진다.

아무튼 간에 33개만 남긴 전처리파일을 기존 0.74155가 나오던 코드에 넣어 제출하니 0.74167이 나오며 순간적으로 100등 이내에 진입했다.
삭제만으로 점수가 이렇게 오를 수 있다는 사실이 데이터 관련 대회를 처음 진행해본 나로서는 너무나도 신기했다.

이후 optuna 의 trial 수를 늘려가며 조금이라도 점수를 올리기 위한 노력을 했으나 최대 0.74171까지 나오며 이 이상의 발전은 없었다. (당시 30등 대 정도의 점수)


#### 4. 하이퍼 파라미터 튜닝에 Bootstrap type 추가 & 캘리브레이션 후처리 추가

아무래도 3번 과정까지 진행하고 나면 어느 정도 아이디어가 막히게 되다보니 gpt와 deepseek를 적절하게 사용해가며 아이디어를 찾아보았다.
당시 얻어낸 정보가 파라미터 튜닝에 더 많은 파라미터를 쓸 수 있다는 점과(이 중 하나가 부트스트랩 타입 설정), 예측 결과값이 한쪽으로 쏠리지 않게 적절히 결과값을 보정해주는
캘리브레이션 후처리라는 기능이 있었다.

먼저 Bootstrap type 에 경우 다음 네 종류가 있다.

![alt text](img/에이머스/image2.png)

어차피 가장 잘 나오는 타입이 알아서 선택되긴하지만 역시나 설명대로 validation 스코어 최고점을 찍는 것은 언제나 Poisson 이었다.

이 파라미터를 추가하고, 마지막에 캘리브레이션까지 추가하여 33개만 남긴 전처리 파일을 넣어 제출했더니 0.7418점이 나왔다. (최고 점수이자 더 이상 깰 수 없었던 점수)
당시 6~70등 라인이었기에 굉장히 희망찼고, 대회도 1주일 이상 남아 조금만 더 하면 정말 안정적으로 오프라인 본선에 갈 수 있겠다고 생각했다.

아, 참고로 '임신 성공 여부'를 예측해야 하는 문제이나 train 데이터셋 내의 임신 실패 : 성공 비율이 3 대 1이었기에,
class_weights 가중치 설정을 실패:성공 = 1:3 으로 잡아주었다. (정확히는 1을 기준으로 나눴기에 0.25:0.75 로 두었음)


#### 5. 다시 전처리로 돌아가기

위 설명에는 없으나 기존에 결측값도 상당히 많았는데 이에 대한 처리는 적절히 중앙값 혹은 최빈값으로 채워넣었었다.
굉장히 단순한 방법으로 채워넣었다고 생각하여, 결측값을 채우는 방식부터 다시 생각해보았다.

1. knn으로 채우기
-> 데이터의 결측값을 채울 때, 그 값과 가장 가까운 주변의 k개의 데이터를 보고 그 평균값으로 채워 넣는 방법이다.
   데이터의 양도 상당하고, 비선형적이다보니 단순히 중앙값 최빈값으로 채워넣는 것보단 훨씬 더 점수 향상을 기대해볼 법했다.
   하지만 점수가 좀 많이 떨어졌다 최고점(0.7418) 코드를 베이스로 하여, 결측치 보간 방식만 knn으로 수정했을 때 평균적으로 0.7412점이 나왔다.
   n_neighbors(결측치를 채울 때 참고할 이웃의 개수) 의 수를 4~7까지 조정해가며 점수를 확인했지만 낮은 점수에서 머물기만 할 뿐이었다.

2. mice로 채우기 
-> knn에 비해 좀 더 정교하고 복잡한 방식이다. mice의 동작 방식은 다음과 같다.
   (1) 결측치가 있는 부분을 대충 평균값 같은 걸로 채운다.
   (2) 결측치가 있는 열을 하나씩 골라서, 그 열의 결측치를 다른 열들의 정보를 보고 예측한다. 그 뒤 또 다른 열로 넘어가 반복
   (3) 위 과정을 여러 번 돌면서 점점 더 정확한 값으로 채워 넣게 됨
   (4) 마지막으로 여러 번 시도한 결과들을 종합하여 최종값을 만듦.

   변수 간 관계를 모델로 예측하기 때문에 knn에 비해 좀 더 현실적인(?) 값을 채우는 게 이론상 가능하다.

   하지만 점수는 knn 방식과 별 다를 바 없었다. 그냥 이제는 대체 왜 어렵지도 않은 대충 채워넣은 평균값 최빈값이 점수가 가장 잘 나오는지가 궁금해진다.


#### 6. 마무리

결국 위 과정들을 여러 번 반복하다 보니 어느새 대회가 마무리 되었다. 
느낀 점이 여러가지가 있지만 이런 대회를 다시 참여한다면, 어차피 베이스라인 코드, 모델관련 처리는 금방하니 정말 최소한으로만 만들어놓고 무조건
전처리가 가장가장 중요한 것 같다. 전처리만으로 큰 점수 획득을 하기 전까지는 코드에 신경을 잠시 덜어두고 전처리에 크게 집중해야 한다는 것을 깨달았다.
무엇보다도 타 대회의 수상자들은 '파생 변수'를 만들어 점수를 크게 올렸다고 했는데, 나는 이번 대회에서 점수에 이득이 되는 파생 변수를 단 하나도 찾지 못했다.
코드 공유가 올라오게 된다면 어떤 파생 변수를 어떤 목적으로 만들었는지 파헤치며, 다른 대회에서도 유용하게 써먹을 수 있는 지식을 얻고 싶다.
