## Medical Data Classification Assited by Machine Learning Startegy 논문 리뷰

![alt text](img/의료데이터분류/image.png)

'머신러닝 전략을 활용한 의료 데이터 분류'

![alt text](img/의료데이터분류/의료데이터.png)

과학기술의 발전과 함께 의료 분야에서도 방대한 양의 데이터가 수집·분석되고 있으며, 이를 기반으로 한 고정밀 컴퓨터 보조 진단이 활발히 이루어지고 있다. 특히 의료 데이터는 환자의 병변 위치를 정확하게 파악하고, 진료 과정에서 의사의 업무를 지원하여 진단의 효율성과 정확도를 높이는 데 큰 기여를 하고 있다.

![alt text](img/의료데이터분류/얕은구조.png)

![alt text](img/의료데이터분류/일반화능력.png)

하지만 의료 데이터는 고차원성, 높은 노이즈, 강한 특성 간 상관관계 등의 복잡한 특성을 지니고 있어 기존의 전통적인 머신러닝 기반 분류 알고리즘으로는 높은 분류 정확도를 달성하는 데 한계가 있다. 얕은 구조를 기반으로 하는 기존 모델은 제한된 데이터 샘플만으로는 복잡한 패턴을 효과적으로 학습하기 어렵고, 모델의 일반화 능력이 떨어지는 문제가 발생한다.

![alt text](img/의료데이터분류/CNN.png)

이러한 한계를 극복하기 위해 심층 신경망을 포함한 다양한 딥러닝 기반 접근법이 제안되고 있으며, 그 중 CNN(합성곱 신경망)은 의료 데이터 분류 분야에서 뛰어난 성능을 보이며 널리 사용되고 있다. CNN은 계층 간의 효율적인 연결 구조와 지역적 특징 추출 능력을 통해 고차원 의료 데이터에서도 효과적인 특징 학습과 높은 분류 성능을 보여준다.
본 논문에서는 CNN 기반의 새로운 의료 데이터 분류 모델을 설계하고, 기존 방법들과 비교하여 더 높은 분류 정확도, 더 빠른 학습 수렴 속도, 더 낮은 학습 오류를 달성했음을 실험을 통해 검증하였다.

본 논문의 주요 기여점

1. 심층 모델에 기반하여 대규모 의료 데이터 분류를 처리할 수 있다.
2. 실험 결과는 제안한 방법의 효과성과 실용성을 입증한다. 다시 말해, 본 논문에서 제안한 방법은 이론적 가치와 실용적 의미를 모두 지닌다.

![alt text](img/의료데이터분류/풀링층.png)

기존의 완전 연결 신경망을 기반으로 CNN은 합성곱층과 풀링층을 추가하여 심층 CNN 모델을 형성하였다. 합성곱층은 주로 이미지의 특징을 추출하는 역할을 하며, 합성곱 커널은 필터행렬로, 원본 이미지에 다양한 효과를 적용할 수 있다.

CNN은 합성곱 후 비선형 함수의 특징 맵핑, 즉 이미지 속 복잡한 패턴을 더 잘 잡아내기 위해, 활성화 함수를 적용한다. 활성화 함수란 입력 신호의 총합을 출력 신호로 변환하는 함수를 뜻하는데, 이는 단순한 선형 계산만으로는 표현할 수 없는 다양한 특징들을 모델이 학습할 수 있게 해준다. 예를 들어, 선형 함수만 사용할 경우 출력이 항상 입력에 비례하게 되는데, 이렇게 되면 네트워크가 아무리 깊어져도 결국 전체 모델은 하나의 선형 함수처럼 동작하게 된다. 이렇게 되면 모델이 복잡한 구조나 비정형적인 패턴을 인식하는 데에 한계가 생긴다.

하지만 비선형 함수를 중간에 넣어줌으로써, 모델이 훨씬 더 다양한 형태의 데이터를 분류하고 인식할 수 있게 되어 다양한 특징을 효과적으로 학습할 수 있게 된다.

#### 비선형 함수 3가지

1. sigmoid

![alt text](img/의료데이터분류/sigmoid.png)

첫 번째는 시그모이드 입니다. sigmoid의 뜻 자체가 'S자 모양' 이라는 뜻으로, 
그림에서 알 수 있듯이 S자 형태의 그래프를 띠고 있다.

실수 값을 입력받으면 0에서 1사이의 값으로 압축하며 큰 음수 값일 수록 0에 가까워지고 큰 양수 값일 수록 1이 되는 특징이 있다.
다만, 시그모이드 함수의 기울기는 입력이 0일 때 가장 크고, x값의 절댓값이 커질수록 기울기가 0에 수렴하게 된다. 기울기가 너무 작아지면 파라미터가 거의 업데이트되지 않아 학습이 느려지거나 멈추게 되는 문제가 있다.

2. tanh 

![alt text](img/의료데이터분류/tanh.png)

두 번째는 tanh(탄에이치). 시그모이드와 비슷하지만 0에서 1사이의 값이 아닌 -1에서 1사이의 값으로 압축한다. 압축 범위만 다를 뿐 그래프의 모양은 시그모이드와 동일하여 시그모이드 함수와 같이 학습이 느려지거나 멈추게 되는 문제가 발생한다.

![alt text](img/의료데이터분류/ReLU.png)

세 번째는 ReLU 입니다. 가장 많이 사용하는 활성화 함수로 입력이 0을 넘으면 그대로 출력하고, 0 이하라면 0을 출력하는 함수이다. 
ReLU를 가장 많이 사용하는 이유는 다음과 같다.
먼저 위 두개의 함수와는 달리 x>0 일때 기울기 소실 문제가 없다. x>0 일때 기울기값은 1이기 때문에 기울기 소실없이 네트워크에서 전달이 잘 된다. 다음으로는 지수 함수가 없기 때문에 연산 비용이 낮고 구현이 간단하다. 시그모이드와 tanh를 보면 알 수 있듯이 계산식에 지수 함수가 있어 상대적으로 연산 비용이 높은 편이다.
그리고 ReLU는 음수 입력에 대해 0을 출력함로 뉴런의 일부가 비활성화 된다. 이는 계산의 효율성을 증가시키고 과적합을 방지하는 효과가 있다.
마지막으로는 여러 논문과 실험에서 확인된 결과로서, 시그모이드보다 빠르게 수렴한다. 라는 장점이 있다.

하지만 이런 ReLU도 문제점이 있는데, 바로 어떤 뉴런에 계속해서 0 이하의 값이 들어온다면, 그 뉴런은 계속해서 출력이 0이 되는 일명 '죽은 뉴런'이 된다는 것이다. 이렇게 되면 기울기도 계속 0이기 때문에 업데이트가 전혀 안되어서 학습에서도 완전히 배제된다는 문제가 있다. 따라서 이러한 문제를 해결하는 현재까지 나온 활성화 함수 중 가장 상위 버전이라 할 수 있는 Leaky ReLU가 있다. 

![alt text](img/의료데이터분류/Leaky.png)

이는 기본 렐루와 달리 음수 영역에서도 완전히 꺼지지 않고 작은 기울기를 가지게 하여 음수 입력에도 뉴런히 죽지 않게 되고, 모든 입력에 대해 기울기가 존재하므로 학습이 부드럽게 이어진다. 따라서 이 논문에서도 분류 작업을 위해 활성화 함수는 Leaky ReLU를 사용하였다.

![alt text](img/의료데이터분류/은닉층.png)

위에 까지는 
은닉층의 이야기이고, 출력층에서는 활성화 함수로 softmax를 사용한다.









