## 데이터 전처리

```python
# 선택한 열을 제거함
df.drop(axis=0/1, inplace=False/True)
```

```python
# 선택한 열을 제거함, 주로 딕셔너리 형태
df.replace({'수정하려는 값' : '수정된 값'}, inplace=False/True)
```

```python
# 결측값 대체
df['열이름'].fillna('바뀌는 값', inplace=False/True)
```

```python
# 데이터 프레임 열 타입 변환
df['열이름'] = df['열이름'].astype(type)
```


## 그룹 집계

```python
# 그룹별로 원하는 열을 집계함
# by : 그룹의 기준이 되는 열 
# 집계함수 : sum, mean, count 등
df.groupby(by=['그룹의 기준이 되는 열'])['집계의 대상이 되는 열'].sum/mean/count()
```


## 정규화와 표준화

```python
from sklearn.preprocessing import MinMaxScaler
data = MinMaxScaler()
X_train = data.fit_transform(X_train)
X_test = data.transform(X_test)
```


## 인코딩

1. 라벨 인코딩
```python
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['범주형 열'] = le.fit_transform(df['범주형 열'])
```

2. 원 핫 인코딩
```python
# columns : 원핫 인코딩 적용 열 리스트
# drop_first = True : 첫번째 범주는 제외하고 원핫인코딩 적용
import pandas as pd
df = pd.get_dummies(df, columns=['범주형 열'], drop_first=True)
```


## 모델링 및 성능 평가

1. 데이터 분할
```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=42)
```


2. 모델 학습
```python
model.fit(X_train, y_train)
```

3. 모델 검증
```python
model.score(X_test, y_test)
```

4. 모델 예측
```python
model.predict(X_test)
```

5. 모델 검증
```python
from sklearn.metrics import  # 이렇게만 치면 모든 함수 로드

from sklearn.metrics import accuracy_score       # 정확도 
from sklearn.metrics import precision_score      # 정밀도
from sklearn.metrics import recall_score         # 재현율
from sklearn.metrics import f1_score             # f1 score
from sklearn.metrics import confusion_matrix     # 혼동행렬
from sklearn.metrics import accuracy_score       # 모든 지표 한번에

from sklearn.metrics import r2_score             # R2 결정계수
from sklearn.metrics import mean_squared_error   # MSE
from sklearn.metrics import mean_absolute_error  # MAE
```

## 머신러닝 모델링

1. 로지스틱 회귀, 분류
```python
from sklearn.linear_model import LogisticRegression
lg = LogisticRegression(C=1.0, max_iter=1000)
lg.fit(X_train, y_train)
lg.score(X_test, y_test)
```

2. Decstion Tree
```python
from sklearn.tree import DecsionTreeClassifier
from sklearn.tree import DecisionTreeRegressor
dt = DecisionTreeClassifier(max_depth=5, random_state=42)
dt.fit(X_train, y_train)
df.score(X_test, y_test)
```


3. Random Forest
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
rf.score(X_test, y_test)
```


4. XGboost
```python
from xgboost import XGBClassifier
from xgboost import XGBRegressor
xgb = XGBClassifier(n_estimator=100)
xgb.fit(X_train, y_train)
xgb.score(X_test, y_test)
```


5. LightGBM
```python
from lightgbm import LGBMClassifier
from lightgbm import LGBMRegressor
lgbm = LGBMClassifier(n_estimator=100)
lgbm.fit(X_train, y_train)
lgbm.score(X_test_, y_test)
```


## 딥러닝 모델링

tensorflow를 사용합니다.

```python
import tensorflow as tf
from tensorflow import keras
```

1. 모델 생성
Sequential 하게 레이어 쌓기
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.models import Dense, Dropout

model = Sequential()

model.add(Dense(128, input_shape(26,), activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(64, activation='relu'))
model.add(Drouout(0.3))
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.3))

model.add(Dense(1, activation='sigmoid')) 
model.summary()
```

2. 모델 학습
```python
model.compile(optimizer='adam', loss='binary_crossentropy', metric=['accuracy'])
```

```python
from tensorflow.keras.callbacks import EarlyStopping
es = EalryStopping(monitor='val_loss', mode='min')    # monitor : 학습되는지 확인하는 기준, mode : 모델 최적화 기준 최대화/최소화
```

```python
from tensorflow.keras.callbacks import ModelCheckpoint
mc = ModelCheckpoint('my_checkpoibnt.ckpt', monitor='val_loss', mode='min', save_best_only=True)
```

```python
history = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=epochs, batch_size=batch_size, callbacks=[es, mc])
```

```python
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
```