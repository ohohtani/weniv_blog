# 텍스트 분류

텍스트가 입력으로 주어졌을 때, 주어진 텍스트가 어떤 범주에 속하는지 구분하는 작업이다. (이진 or 다중 클래스 분류)

우선 단어를 숫자로 맵핑하여 정수를 부여한다.
빈도수 순으로 정렬한 뒤, 순차적으로 정수를 부여한다. 이렇게 하는 경우 빈도수가 적은 단어를 제거하기에 좋다.

RNN을 통해 분류
```python
model.add(SimpleRNN(hidden_units, input_shape=(timesteps, input_dim)))
```

hidden_units 는 RNN의 출력의 크기이다. (은닉 상태의 크기)
timesteps는 시점의 수. 즉, 각 문서에서의 단어 수이며,
input_dim은 입력의 크기이자 임베딩 벡터의 차원이다.


## 스팸 메일 분류

일반적인 전처리 과정을 거치고 난 데이터셋의 분포는 아래와 같다.

클래스 0(정상 메일) : 4,516개 (87.367%)
클래스 1(스팸 메일) : 653개 (12.633%)

클래스 불균형이므로 stratify를 사용해 레이블 분포가 고르게 되도록 해준다
```python
X_train, X_test, y_trian, y_test = train_test_split(X, y, test_size=0.2, stratify=y)
```

이후, 케라스 토크나이저를 통해 훈련 데이터를 토큰화하고 정수 인코딩한다.
```python
tokenizer = Tokenizer()
tokenizer.fit_on_texts(X_train)
X_train_encoded = tokenizer.texts_to_sequences(X_train)
```

정수 인코딩 된 결과를 확인하면 빈도수가 높을 수록 낮은 정수가 부여된 결과를 확인할 수 있다.
추가적으로 빈도수가 낮은 단어들이 차지하는 비중을 확인해볼 수도 있다.
등장 빈도가 1번 이하인 희귀 단어의 수는 4,337 개로 전체 단어 집합에서 약 55.45%를 차지한다. (희귀 단어 종류 수 / 총 단어 종류 수)

그리고 전체 등장 빈도에서 희귀 단어의 등장 빈도는 6.65%이다 (희귀 단어가 등장한 횟수 / 모든 단어의 등장 횟수)

아마 이런식으로 종류에서는 비중이 많은데 실제 등장빈도가 적은 단어들은 제외하는 경향이 있는 것 같다.

그리고 메일들 중에서 가장 긴 길이를 갖는 것과 평균 길이를 출력해볼 수 있다.

![alt text](img/RNN/메일길이.png)

가장 긴 메일의 길이가 189이고, 훈련데이터 셋의 크기는 4,135(전체 메일 5,159개 중 분리한 80%)이므로
4,135개의 X_train_encoded 의 길이를 전부 189로 바꾼다. (189보다 짧으면 0으로 패딩)

## 모델 돌리기

이제 모델에 넣고 돌릴 수 있는 전처리가 완료되었다.

```python
from tensorflow.keras.layers import SimpleRNN, Embedding, Dense
from tensorflow.keras.models import Sequential

embedding_dim = 32
hidden_units = 32

model = Sequential()
model.add(Embedding(vocab_size, embedding_dim))
model.add(SimpleRNN(hidden_units))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
history = model.fit(X_train_padded, y_train, epochs=4, batch_size=64, validation_split=0.2)
```

정확도는 98.21%로 스팸 메일 분류에 있어 훌륭한 성능을 보인다.