# 1D 합성곱

"wait for the video and don't rent it" 이라는 문장이 있다면,

토큰화를 통해
["wait", "for", "the", ..., "it"] 으로 나누고

패딩을 통해 다른 문장들과 길이를 맞추고

임베딩 층을 통과하여 각 단어를 숫자 벡터로 변환하면 문장은 (문장 길이 x 임베딩 차원) 크기의 행렬이 된다.

1D 합성곱의 핵심 아이디어는 단어들을 여러 개씩 묶어서 한 번에 특징을 잡아내는 것이다.
가령 커널 사이즈가 2라고 한다면
"wait"+"for",  "for"+"the",   "the"+"video"  이런 식이다 -> 병렬 처리가 가능해서 학습이 빠르다

![alt text](img/RNN/커널1d.png)

위 사진으로 알 수 있듯 더 이상 커널이 너비 방향으로는 움직일 수 없다.
1D 합성곱 연산에서는 커널이 문장 행렬의 높이 방향으로만 움직이게 되어 있다.

당연하게도 커널의 크기는 달라질 수 있다 -> 참고하게 되는 단어 묶음의 크기를 달리할 수 있다.

![alt text](img/RNN/맥스풀링.png)

이미지처리와 마찬가지로 맥스 풀링 연산을 진행하고

지금까지 배운 개념들을 통해 텍스트 분류를 위한 CNN을 설계한다. 
(이진 분류를 위한 신경망이지만 소프트맥스를 쓸 거임 -> 출력층 뉴런 개수 2)

현재의 예시 문장은 다음과 같다.
"wait for the video and don't rent it"
단어 9개짜리 문장이며, 각 단어는 임베딩 벡터로 변환되어 있다.

맥스 풀링을 이용해 각 커널이 만든 출력 벡터들을 1개로 요약하고,
이 벡터를 출력층에 넣는다. 활성화 함수가 softmax이므로 2개의 출력결과가 나올 것이다 (예 : [0.7, 0.3])

### 케라스로 구현하기

```python
from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D

model = Sequential()
model.add(Conv1D(num_filters, kernel_size, padding='valid', activation='relu'))
model.add(GlobalMaxPooling1D())
```

padding='valid' 는 패딩없음을 의미한다.
padding='same'은 합성곱 연산 후 입력과 동일한 차원을 갖도록 제로 패딩을 추가함

