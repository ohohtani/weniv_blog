# 잘 안잡히는 개념 모두 정리

*Perplexity* : 보통 언어 모델을 평가하기 위한 지표로 활용된다. '헷갈리는 정도'라는 의미로, 
모델의 성능을 비교하기 위해 모델 내에서 자신의 성능을 수치화하여 결과를 내놓음

![alt text](img/자연어개념/perplexity.png)

단어 w1부터 wN 까지의 연쇄적인 확률 = 문장 W가 등장할 확률
음의 1/N 제곱을 해주는 이유는, 이를 해주지 않을 경우 전체확률  P(W)는 기하급수적으로 작아지기 때문에
길이에 따른 공정한 비교를 하기 위해 정규화를 하는 것  =>  값이 낮을 수록 좋은 모델이다.

가령 연쇄적인 확률이 0.01 되었다고 쳤을 때, -1/N 제곱을 해주게 되면, 

1 / (P^1/N) 이 되므로, 100 ^ 1/N 이 된다.  N이 10이라 치면 약 1.58 정도의 값을 갖게 되는데

연쇄적인 확률이 0.0001이 되어 기하급수적으로 작아졌다 해도, 10000 ^ 1/N 값은 2.51 정도의 값을 가지므로, 

확률값이 기하급수적으로 작아져 큰 차이가 날 수 있던 값들을 어느정도 비슷한 수치로 만드는 정규화가 가능해진다.
-----------------------------------------------------------------------------------------------------------

